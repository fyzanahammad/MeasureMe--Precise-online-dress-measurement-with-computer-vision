{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize webcam feed\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for default webcam, change accordingly if you have multiple cameras\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame from webcam.\")\n",
    "        break\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process frame with MediaPipe Pose model\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    # Draw connections between landmarks with custom color\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 0), thickness=2, circle_radius=2),\n",
    "                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2))\n",
    "    \n",
    "    # Display frame with landmarks\n",
    "    cv2.imshow('Body Landmarks Detection', frame)\n",
    "    \n",
    "    # Break the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Load image from local file\n",
    "image_path = 'E:/Github_projects/MeasureMe--Precise-online-dress-measurement-with-computer-vision/2.jpg'\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "# Convert BGR to RGB\n",
    "rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process image with MediaPipe Pose model\n",
    "results = pose.process(rgb_frame)\n",
    "\n",
    "# Draw connections between landmarks with custom color\n",
    "if results.pose_landmarks:\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    annotated_image = frame.copy()\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                              landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                              connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2))\n",
    "\n",
    "    # Display annotated image with landmarks\n",
    "    cv2.imshow('Body Landmarks Detection', annotated_image)\n",
    "    \n",
    "    # Save annotated image with landmarks\n",
    "    output_image_path = '1_annotated.jpg'\n",
    "    cv2.imwrite(output_image_path, annotated_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No landmarks detected in the image.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each landmark in the `results.pose_landmarks.landmark` list corresponds to a specific point on the detected human pose. The values associated with each landmark are as follows:\n",
    "\n",
    "- **x**: The normalized x-coordinate of the landmark within the image frame. It represents the horizontal position of the landmark relative to the width of the image. The value ranges from 0 (left edge of the image) to 1 (right edge of the image).\n",
    "\n",
    "- **y**: The normalized y-coordinate of the landmark within the image frame. It represents the vertical position of the landmark relative to the height of the image. The value ranges from 0 (top edge of the image) to 1 (bottom edge of the image).\n",
    "\n",
    "- **z**: The depth or distance of the landmark from the camera plane. This value is expressed in meters and provides information about the position of the landmark along the z-axis (depth) in 3D space. Negative values typically indicate that the landmark is closer to the camera than the origin of the coordinate system.\n",
    "\n",
    "- **visibility**: The visibility score or confidence level associated with the landmark detection. It represents the likelihood that the landmark is correctly detected by the model. The value ranges from 0 to 1, with higher values indicating higher confidence in the detection.\n",
    "\n",
    "In the provided example, the pixel coordinates `(635, 132)` correspond to the result of converting the normalized coordinates `(0.49626579880714417, 0.18469412624835968)` to pixel coordinates, based on the width and height of the image frame. These pixel coordinates represent the location of the landmark within the image frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOSE: Pixel Coordinates: (635, 132)\n",
      "LEFT_EYE_INNER: Pixel Coordinates: (641, 123)\n",
      "LEFT_EYE: Pixel Coordinates: (644, 123)\n",
      "LEFT_EYE_OUTER: Pixel Coordinates: (648, 124)\n",
      "RIGHT_EYE_INNER: Pixel Coordinates: (629, 124)\n",
      "RIGHT_EYE: Pixel Coordinates: (625, 124)\n",
      "RIGHT_EYE_OUTER: Pixel Coordinates: (621, 124)\n",
      "LEFT_EAR: Pixel Coordinates: (651, 129)\n",
      "RIGHT_EAR: Pixel Coordinates: (617, 130)\n",
      "MOUTH_LEFT: Pixel Coordinates: (642, 144)\n",
      "MOUTH_RIGHT: Pixel Coordinates: (626, 145)\n",
      "LEFT_SHOULDER: Pixel Coordinates: (686, 196)\n",
      "RIGHT_SHOULDER: Pixel Coordinates: (581, 196)\n",
      "LEFT_ELBOW: Pixel Coordinates: (747, 249)\n",
      "RIGHT_ELBOW: Pixel Coordinates: (511, 240)\n",
      "LEFT_WRIST: Pixel Coordinates: (816, 277)\n",
      "RIGHT_WRIST: Pixel Coordinates: (436, 250)\n",
      "LEFT_PINKY: Pixel Coordinates: (840, 283)\n",
      "RIGHT_PINKY: Pixel Coordinates: (412, 256)\n",
      "LEFT_INDEX: Pixel Coordinates: (841, 279)\n",
      "RIGHT_INDEX: Pixel Coordinates: (412, 252)\n",
      "LEFT_THUMB: Pixel Coordinates: (833, 277)\n",
      "RIGHT_THUMB: Pixel Coordinates: (421, 251)\n",
      "LEFT_HIP: Pixel Coordinates: (660, 347)\n",
      "RIGHT_HIP: Pixel Coordinates: (602, 346)\n",
      "LEFT_KNEE: Pixel Coordinates: (665, 467)\n",
      "RIGHT_KNEE: Pixel Coordinates: (594, 468)\n",
      "LEFT_ANKLE: Pixel Coordinates: (675, 573)\n",
      "RIGHT_ANKLE: Pixel Coordinates: (593, 577)\n",
      "LEFT_HEEL: Pixel Coordinates: (670, 588)\n",
      "RIGHT_HEEL: Pixel Coordinates: (599, 591)\n",
      "LEFT_FOOT_INDEX: Pixel Coordinates: (691, 602)\n",
      "RIGHT_FOOT_INDEX: Pixel Coordinates: (583, 609)\n"
     ]
    }
   ],
   "source": [
    "# Extract and print pixel coordinates of landmarks\n",
    "if results.pose_landmarks:\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        h, w, c = frame.shape\n",
    "        cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "        landmark_name = mp_pose.PoseLandmark(idx).name\n",
    "        print(f\"{landmark_name}: Pixel Coordinates: ({cx}, {cy})\")\n",
    "else:\n",
    "    print(\"No landmarks detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
